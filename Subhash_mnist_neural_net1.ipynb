{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMhzVlMwnoH28oxD05C8zLp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/subhashbs36/DeepLearning_Colab/blob/main/Subhash_mnist_neural_net1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sfeKwd_-99ue",
        "outputId": "14a67a49-e4c5-430d-ef3b-cbfd93bc9036"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/719.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.3/719.8 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m716.8/719.8 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m719.8/719.8 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mMounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "#hide\n",
        "! [ -e /content ] && pip install -Uqq fastbook\n",
        "import fastbook\n",
        "fastbook.setup_book()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#hide\n",
        "from fastai.vision.all import *\n",
        "from fastbook import *\n",
        "\n",
        "matplotlib.rc('image', cmap='Greys')"
      ],
      "metadata": {
        "id": "ZzSvnGHl-Fgm"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = untar_data(URLs.MNIST_SAMPLE)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "CdThV626-FdG",
        "outputId": "e87bb10f-59fb-4af4-e976-013cc53a1daa"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      <progress value='3219456' class='' max='3214948' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.14% [3219456/3214948 00:00&lt;00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#hide\n",
        "Path.BASE_PATH = path"
      ],
      "metadata": {
        "id": "Gn89Sv5R-Fay"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "threes = (path/'train'/'3').ls().sorted()\n",
        "sevens = (path/'train'/'7').ls().sorted()\n",
        "threes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R5z7W4qG-3SX",
        "outputId": "1446eb4b-46c9-41ae-abe2-3f8801ce44fd"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#6131) [Path('train/3/10.png'),Path('train/3/10000.png'),Path('train/3/10011.png'),Path('train/3/10031.png'),Path('train/3/10034.png'),Path('train/3/10042.png'),Path('train/3/10052.png'),Path('train/3/1007.png'),Path('train/3/10074.png'),Path('train/3/10091.png')...]"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "valid_threes = (path/'valid'/'3').ls().sorted()\n",
        "valid_sevens = (path/'valid'/'7').ls().sorted()\n",
        "valid_threes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4gCHyIdB-3Pn",
        "outputId": "70ecd267-9d51-46c6-8592-3a798b4dbb39"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#1010) [Path('valid/3/1020.png'),Path('valid/3/1028.png'),Path('valid/3/1042.png'),Path('valid/3/1062.png'),Path('valid/3/1066.png'),Path('valid/3/1067.png'),Path('valid/3/1069.png'),Path('valid/3/1072.png'),Path('valid/3/1092.png'),Path('valid/3/1095.png')...]"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stacked_threes = torch.stack([tensor(Image.open(i)) for i in threes]).float()/255\n",
        "stacked_sevens = torch.stack([tensor(Image.open(i)) for i in sevens]).float()/255"
      ],
      "metadata": {
        "id": "BrmT8OYj-3Mq"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stacked_valid_threes = torch.stack([tensor(Image.open(i)) for i in valid_threes]).float()/255\n",
        "stacked_valid_sevens = torch.stack([tensor(Image.open(i)) for i in valid_sevens]).float()/255"
      ],
      "metadata": {
        "id": "cwECROcr-736"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = torch.cat([stacked_threes, stacked_sevens]).view(-1, 28*28)\n",
        "y_train = tensor([1]*len(threes) + [0]*len(sevens)).unsqueeze(1)\n",
        "x_train.shape, y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UxUv6Zp2-7rn",
        "outputId": "ee659861-0cbc-40cf-84ba-881e570c0a0b"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([12396, 784]), torch.Size([12396, 1]))"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_valid = torch.cat([stacked_valid_threes, stacked_valid_sevens]).view(-1, 28*28)\n",
        "y_valid = tensor([1]*len(valid_threes) + [0]*len(valid_sevens)).unsqueeze(1)\n",
        "x_valid.shape, y_valid.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNxrtgGf-7o3",
        "outputId": "f9c84458-73fd-41ef-fa4f-aeed4c1844bf"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([2038, 784]), torch.Size([2038, 1]))"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dset = list(zip(x_train, y_train))\n",
        "valid_dset = list(zip(x_valid, y_valid))\n",
        "\n",
        "dl = DataLoader(dset, batch_size=256)\n",
        "valid_dl = DataLoader(valid_dset, batch_size=256)"
      ],
      "metadata": {
        "id": "cO4OfXVG_LOK"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Building A Optimizer from Scratch Core**"
      ],
      "metadata": {
        "id": "xPdleqCdEXJm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "linear_model = nn.Linear(28*28, 1)\n",
        "lr = 0.01"
      ],
      "metadata": {
        "id": "cSTIF__X-FYO"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mnist_loss(predicted, target):\n",
        "  predicted = predicted.sigmoid()\n",
        "  return torch.where(target==1, 1-predicted, predicted).mean()"
      ],
      "metadata": {
        "id": "oG1xRDwI-FVe"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class basicOpti():\n",
        "  def __init__(self, params, lr):\n",
        "    self.params = list(params)\n",
        "    self.lr = lr\n",
        "\n",
        "  def step(self):\n",
        "    for p in self.params:\n",
        "      p.data -= p.grad * self.lr\n",
        "\n",
        "  def zero_grad(self):\n",
        "    for p in self.params:\n",
        "      p.grad.zero_()"
      ],
      "metadata": {
        "id": "Hr6YwVnr-FS9"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_grad(xb, yb, model):\n",
        "  pred = model(xb)\n",
        "  loss = mnist_loss(pred, yb)\n",
        "  loss.backward()"
      ],
      "metadata": {
        "id": "uAJti3sZ-FQP"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def batch_accuracy(xa, ya):\n",
        "  predicted = xa.sigmoid()\n",
        "  correct = (predicted>0.5) == ya\n",
        "  return correct.float().mean()"
      ],
      "metadata": {
        "id": "eZcdVTRA-FNZ"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = basicOpti(linear_model.parameters(), lr)"
      ],
      "metadata": {
        "id": "s0yD-mg9-olH"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(model):\n",
        "  for xa, ya in dl:\n",
        "    calc_grad(xa, ya, model)\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()"
      ],
      "metadata": {
        "id": "tfvuOG5S-oh-"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validate_epoch(model):\n",
        "  accuracy = [batch_accuracy(model(xa), ya) for xa, ya in valid_dl]\n",
        "  return round(torch.stack(accuracy).mean().item(), 4)"
      ],
      "metadata": {
        "id": "fWpAkgZQ-oe8"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, epochs):\n",
        "  for epoch in range(epochs):\n",
        "    train_epoch(model)\n",
        "    print(validate_epoch(model), end=' ')"
      ],
      "metadata": {
        "id": "bAmsSXP--obw"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(linear_model, 20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_bzPqykt-oYB",
        "outputId": "4cca264b-acb3-4476-c51a-c9083e813c51"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9057 0.9209 0.9385 0.9521 0.957 0.9604 0.9609 0.9619 0.9614 0.9623 0.9623 0.9623 0.9638 0.9633 0.9633 0.9643 0.9648 0.9653 0.9653 0.9658 "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[link text](https://)fastai provides the `SGD` class which, by default, does the same thing as our `basicOpti`:\n"
      ],
      "metadata": {
        "id": "LKXIuE3oHsCf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "linear_model = nn.Linear(28*28,1)\n",
        "optimizer = SGD(linear_model.parameters(), lr)\n",
        "train_model(linear_model, 20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U0pnSgtrHPZ1",
        "outputId": "a758d337-9321-4b0a-bdbc-1aa0d75b0514"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9379 0.9268 0.9443 0.9546 0.958 0.9604 0.9624 0.9623 0.9619 0.9628 0.9628 0.9633 0.9638 0.9648 0.9643 0.9643 0.9653 0.9657 0.9657 0.9657 "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Now using FastAI**"
      ],
      "metadata": {
        "id": "t-3O2a8NHFOn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "fastai also provides `Learner.fit`, which we can use instead of `train_model`. To create a `Learner` we first need to create a **`DataLoaders`**, by passing in our training and validation **`DataLoader`**s:"
      ],
      "metadata": {
        "id": "QQu3ds7lLion"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = DataLoaders(dl, valid_dl) #Dataloader in Dataloaders"
      ],
      "metadata": {
        "id": "tjyYmDRh-oT1"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learn = Learner(dataset, nn.Linear(28*28, 1), loss_func=mnist_loss, opt_func=SGD, metrics=batch_accuracy)"
      ],
      "metadata": {
        "id": "rrpRpTnHH_Au"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learn.fit(30, lr=0.001)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 990
        },
        "id": "Htp9_MoiJb-P",
        "outputId": "ee5ee510-a263-4460-9514-50c369c29191"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>batch_accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.093161</td>\n",
              "      <td>0.095724</td>\n",
              "      <td>0.962709</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.092875</td>\n",
              "      <td>0.095107</td>\n",
              "      <td>0.963690</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.092553</td>\n",
              "      <td>0.094521</td>\n",
              "      <td>0.963690</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.092210</td>\n",
              "      <td>0.093963</td>\n",
              "      <td>0.963690</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.091858</td>\n",
              "      <td>0.093428</td>\n",
              "      <td>0.964671</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.091504</td>\n",
              "      <td>0.092915</td>\n",
              "      <td>0.965162</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.091153</td>\n",
              "      <td>0.092422</td>\n",
              "      <td>0.965653</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.090805</td>\n",
              "      <td>0.091946</td>\n",
              "      <td>0.965162</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.090462</td>\n",
              "      <td>0.091486</td>\n",
              "      <td>0.965162</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.090122</td>\n",
              "      <td>0.091040</td>\n",
              "      <td>0.965653</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.089785</td>\n",
              "      <td>0.090607</td>\n",
              "      <td>0.965653</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.089452</td>\n",
              "      <td>0.090186</td>\n",
              "      <td>0.965653</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.089122</td>\n",
              "      <td>0.089777</td>\n",
              "      <td>0.965653</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.088795</td>\n",
              "      <td>0.089377</td>\n",
              "      <td>0.965653</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.088470</td>\n",
              "      <td>0.088987</td>\n",
              "      <td>0.965653</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.088148</td>\n",
              "      <td>0.088606</td>\n",
              "      <td>0.965653</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.087829</td>\n",
              "      <td>0.088233</td>\n",
              "      <td>0.965162</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.087512</td>\n",
              "      <td>0.087868</td>\n",
              "      <td>0.965653</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.087197</td>\n",
              "      <td>0.087510</td>\n",
              "      <td>0.965162</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.086885</td>\n",
              "      <td>0.087159</td>\n",
              "      <td>0.965162</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.086575</td>\n",
              "      <td>0.086815</td>\n",
              "      <td>0.965162</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>0.086267</td>\n",
              "      <td>0.086477</td>\n",
              "      <td>0.965162</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>0.085962</td>\n",
              "      <td>0.086144</td>\n",
              "      <td>0.965162</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>0.085660</td>\n",
              "      <td>0.085818</td>\n",
              "      <td>0.965162</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>0.085359</td>\n",
              "      <td>0.085497</td>\n",
              "      <td>0.965162</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>0.085061</td>\n",
              "      <td>0.085181</td>\n",
              "      <td>0.965162</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>0.084766</td>\n",
              "      <td>0.084870</td>\n",
              "      <td>0.964671</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>0.084473</td>\n",
              "      <td>0.084564</td>\n",
              "      <td>0.964671</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>0.084182</td>\n",
              "      <td>0.084262</td>\n",
              "      <td>0.964671</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>0.083894</td>\n",
              "      <td>0.083966</td>\n",
              "      <td>0.964671</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Building a Simple NN using FastAI**"
      ],
      "metadata": {
        "id": "vdrJebtmEgt5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random Initializer with Grad for parameter initializing"
      ],
      "metadata": {
        "id": "Ygo77NvVNP4S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def init_params(size, std=1.0):\n",
        "  return (torch.randn(size)*std).requires_grad_()"
      ],
      "metadata": {
        "id": "Mx8ha_4-GYoq"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Adding a Nonlinearity"
      ],
      "metadata": {
        "id": "8dEMi85FMeWF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "So far we have a general procedure for optimizing the parameters of a function, and we have tried it out on a very boring function: a simple linear classifier. A linear classifier is very constrained in terms of what it can do. To make it a bit more complex (and able to handle more tasks), we need to add something nonlinear between two linear classifiers—this is what gives us a neural network.\n",
        "\n",
        "Here is the entire definition of a basic neural network:"
      ],
      "metadata": {
        "id": "9RUKDJggMRNb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def simple_net(xb):\n",
        "    res = xb@w1 + b1\n",
        "    res = res.max(tensor(0.0)) #or F.relu(res)\n",
        "    res = res@w2 + b2\n",
        "    return res"
      ],
      "metadata": {
        "id": "pIuyyBpiGNOx"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w1 = init_params((28*28,30))\n",
        "b1 = init_params(30)\n",
        "w2 = init_params((30,1))\n",
        "b2 = init_params(1)"
      ],
      "metadata": {
        "id": "2OKFrokjGNKC"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The key point about this is that `w1` has 30 output activations (which means that `w2` must have 30 input activations, so they match). That means that the first layer can construct 30 different features, each representing some different mix of pixels. You can change that `30` to anything you like, to make the model more or less complex.\n",
        "\n",
        "That little function `res.max(tensor(0.0))` is called a *rectified linear unit*, also known as *ReLU*. We think we can all agree that *rectified linear unit* sounds pretty fancy and complicated... But actually, there's nothing more to it than `res.max(tensor(0.0))`—in other words, replace every negative number with a zero. This tiny function is also available in PyTorch as `F.relu`:"
      ],
      "metadata": {
        "id": "UE-YS-c4M_Mm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using PyTorch Build Simple NN"
      ],
      "metadata": {
        "id": "nYuVPxfLOEiE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "simple_net = nn.Sequential(\n",
        "    nn.Linear(28*28, 30),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(30, 1)\n",
        ")"
      ],
      "metadata": {
        "id": "uwE9VSj1GNF6"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`nn.Sequential` creates a module that will call each of the listed layers or functions in turn.\n",
        "\n",
        "`nn.ReLU` is a PyTorch module that does exactly the same thing as the `F.relu` function. Most functions that can appear in a model also have identical forms that are modules. Generally, it's just a case of replacing `F` with `nn` and changing the capitalization. When using `nn.Sequential`, PyTorch requires us to use the module version. Since modules are classes, we have to instantiate them, which is why you see `nn.ReLU()` in this example.\n",
        "\n",
        "Because `nn.Sequential` is a module, we can get its parameters, which will return a list of all the parameters of all the modules it contains. Let's try it out! As this is a deeper model, we'll use a lower learning rate and a few more epochs."
      ],
      "metadata": {
        "id": "5DqF-pOfOv8x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learn = Learner(dataset, simple_net, loss_func=mnist_loss, opt_func=SGD, metrics=batch_accuracy)"
      ],
      "metadata": {
        "id": "80mZgn0oGNBd"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#hide_output\n",
        "learn.fit(40, 0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ecxDuUkhGM6-",
        "outputId": "7d4debc6-4265-4ffe-d9e5-20d2ee8c8378"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>batch_accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.312166</td>\n",
              "      <td>0.404465</td>\n",
              "      <td>0.506379</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.145596</td>\n",
              "      <td>0.231331</td>\n",
              "      <td>0.802257</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.080657</td>\n",
              "      <td>0.115488</td>\n",
              "      <td>0.915604</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.052939</td>\n",
              "      <td>0.077457</td>\n",
              "      <td>0.943081</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.040113</td>\n",
              "      <td>0.060312</td>\n",
              "      <td>0.955348</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.033582</td>\n",
              "      <td>0.050774</td>\n",
              "      <td>0.965653</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.029834</td>\n",
              "      <td>0.044804</td>\n",
              "      <td>0.966143</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.027405</td>\n",
              "      <td>0.040724</td>\n",
              "      <td>0.968106</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.025659</td>\n",
              "      <td>0.037764</td>\n",
              "      <td>0.970069</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.024312</td>\n",
              "      <td>0.035506</td>\n",
              "      <td>0.971050</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.023222</td>\n",
              "      <td>0.033720</td>\n",
              "      <td>0.973503</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.022314</td>\n",
              "      <td>0.032260</td>\n",
              "      <td>0.973994</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.021540</td>\n",
              "      <td>0.031035</td>\n",
              "      <td>0.973503</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.020869</td>\n",
              "      <td>0.029988</td>\n",
              "      <td>0.974485</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.020281</td>\n",
              "      <td>0.029075</td>\n",
              "      <td>0.974975</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.019759</td>\n",
              "      <td>0.028270</td>\n",
              "      <td>0.975466</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.019290</td>\n",
              "      <td>0.027552</td>\n",
              "      <td>0.976448</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.018867</td>\n",
              "      <td>0.026907</td>\n",
              "      <td>0.976938</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.018481</td>\n",
              "      <td>0.026324</td>\n",
              "      <td>0.977429</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.018127</td>\n",
              "      <td>0.025795</td>\n",
              "      <td>0.978410</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.017801</td>\n",
              "      <td>0.025313</td>\n",
              "      <td>0.980373</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>0.017500</td>\n",
              "      <td>0.024871</td>\n",
              "      <td>0.980373</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>0.017219</td>\n",
              "      <td>0.024465</td>\n",
              "      <td>0.980373</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>0.016956</td>\n",
              "      <td>0.024091</td>\n",
              "      <td>0.980864</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>0.016711</td>\n",
              "      <td>0.023745</td>\n",
              "      <td>0.980864</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>0.016480</td>\n",
              "      <td>0.023425</td>\n",
              "      <td>0.980864</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>0.016262</td>\n",
              "      <td>0.023127</td>\n",
              "      <td>0.980864</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>0.016055</td>\n",
              "      <td>0.022851</td>\n",
              "      <td>0.980864</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>0.015860</td>\n",
              "      <td>0.022593</td>\n",
              "      <td>0.980864</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>0.015675</td>\n",
              "      <td>0.022352</td>\n",
              "      <td>0.980864</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.015499</td>\n",
              "      <td>0.022127</td>\n",
              "      <td>0.981845</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>0.015331</td>\n",
              "      <td>0.021917</td>\n",
              "      <td>0.981845</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>0.015170</td>\n",
              "      <td>0.021719</td>\n",
              "      <td>0.982336</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>0.015017</td>\n",
              "      <td>0.021533</td>\n",
              "      <td>0.982336</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>0.014870</td>\n",
              "      <td>0.021358</td>\n",
              "      <td>0.982336</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>0.014729</td>\n",
              "      <td>0.021193</td>\n",
              "      <td>0.982336</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>0.014593</td>\n",
              "      <td>0.021037</td>\n",
              "      <td>0.982826</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>0.014463</td>\n",
              "      <td>0.020889</td>\n",
              "      <td>0.982826</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>0.014336</td>\n",
              "      <td>0.020749</td>\n",
              "      <td>0.982826</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>0.014215</td>\n",
              "      <td>0.020616</td>\n",
              "      <td>0.982826</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}